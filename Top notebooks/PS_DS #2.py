# -*- coding: utf-8 -*-
"""Dataverse Claim Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lHd49cwnTgxIOmaLhjQ39zI1kshimzV-

### Imports
"""

!pip install category-encoders

!wget https://datahack-prod.s3.amazonaws.com/sample_submission/sample_submission_KvRh9Sx.csv
!wget https://datahack-prod.s3.amazonaws.com/train_file/train_qWM28Yl.csv
!wget https://datahack-prod.s3.amazonaws.com/test_file/test_zo1G9sv.csv

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split,cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix
from xgboost import plot_importance,XGBClassifier
import category_encoders as ce
import matplotlib.pyplot as plt

pd.set_option('display.max_columns', None)

def performance(true,pred):
  print('f1 score ',f1_score(true,pred))
  print('Precision ',precision_score(true,pred))
  print('Recall ',recall_score(true,pred))
  print('Accuracy ',accuracy_score(true,pred))
  print(confusion_matrix(true,pred))

"""### Load Data"""

train = pd.read_csv('train_qWM28Yl.csv')
test = pd.read_csv('test_zo1G9sv.csv')
sub = pd.read_csv('sample_submission_KvRh9Sx.csv')

train.shape,test.shape

train.isna().sum().sum(),test.isna().sum().sum()

for col in test.columns:
  if col.startswith('is'):
    train[col].replace({'Yes':1,'No':0},inplace=True)
    test[col].replace({'Yes':1,'No':0},inplace=True)

sum(train['is_claim'] == 1)/train.shape[0]

for col in test.columns:
  if train[col].nunique() < 50:
    tmp = pd.crosstab(train[col],train['is_claim']).reset_index()
    tmp['Total_Claim'] = tmp[0] + tmp[1]
    tmp['Total_Claim_Dist'] = 100*tmp['Total_Claim']/tmp['Total_Claim'].sum()
    tmp['claim_ratio'] = 100*tmp[1]/tmp['Total_Claim']
    tmp['claim_dist'] = 100*tmp[1]/tmp[1].sum()
    tmp['Non_Claim_dist'] = 100*tmp[0]/tmp[0].sum()
    display(tmp)
  else:
    try:
      tmp = train.groupby(['is_claim']).agg({col:'describe'}).reset_index()
      display(tmp)
    except:
      print(col)

train.shape,train['policy_id'].nunique(),train['policy_tenure'].nunique()

test.shape,test['policy_tenure'].nunique()

"""## Feature Engineering"""

train[['Nm','rpm_torque']] = train['max_torque'].str.split('@',expand=True)
test[['Nm','rpm_torque']] = test['max_torque'].str.split('@',expand=True)

train['Nm'] = train['Nm'].apply(lambda x: float(x[:-2]))
test['Nm'] = test['Nm'].apply(lambda x: float(x[:-2]))

train['rpm_torque'] = train['rpm_torque'].apply(lambda x: float(x[:-3]))
test['rpm_torque'] = test['rpm_torque'].apply(lambda x: float(x[:-3]))

train[['bhp','rpm_power']] = train['max_power'].str.split('@',expand=True)
test[['bhp','rpm_power']] = test['max_power'].str.split('@',expand=True)

train['bhp'] = train['bhp'].apply(lambda x: float(x[:-3]))
test['bhp'] = test['bhp'].apply(lambda x: float(x[:-3]))

train['rpm_power'] = train['rpm_power'].apply(lambda x: float(x[:-3]))
test['rpm_power'] = test['rpm_power'].apply(lambda x: float(x[:-3]))

for i in [train,test]:
  i['weight_per_area'] = i['gross_weight']/(i['length']*i['width']*i['height'])
  i['Nm_rpm'] = i['rpm_torque']/i['Nm']
  i['bhp_rpm'] = i['rpm_power']/i['bhp']
  i['age'] = (i['age_of_car']/i['age_of_policyholder'])

# num_col = ['policy_tenure','age',#'age_of_car', 'age_of_policyholder',
#         'population_density', 'make',   'airbags','is_esc', 'is_adjustable_steering', 'is_tpms', 'is_parking_sensors',
#        'is_parking_camera',
#         'displacement', 'cylinder',
#         'gear_box',  'turning_radius',
#        'is_front_fog_lights',
#        'is_rear_window_wiper', 'is_rear_window_washer',
#        'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks',
#        'is_central_locking', 'is_power_steering',
#        'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror',
#        'is_ecw', 'is_speed_alert',  'ncap_rating','weight_per_area','Nm_rpm','bhp_rpm']

# cat_col = ['area_cluster','segment', 'model',
#        'fuel_type','engine_type',
#        'rear_brakes_type','transmission_type','steering_type']

num_col = ['policy_tenure','age',#'age_of_car', 'age_of_policyholder',
        'population_density', 'make',   'airbags','is_esc', 'is_adjustable_steering', 'is_tpms', 'is_parking_sensors',
       'is_parking_camera',
        'displacement', 'cylinder',
          'turning_radius',
       'is_front_fog_lights',
       'is_rear_window_wiper', 'is_rear_window_washer',
       'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks',
       'is_central_locking', 'is_power_steering',
       'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror',
       'is_ecw', 'is_speed_alert',  'weight_per_area','Nm_rpm','bhp_rpm']

cat_col = ['area_cluster','segment', 'model',
       'fuel_type','engine_type',
       'rear_brakes_type','transmission_type','steering_type','gear_box','ncap_rating']

"""### Preparation for Modelling"""

X=train[num_col + cat_col]
y=train['is_claim']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, stratify=y)

ce_target = ce.TargetEncoder(cols=cat_col)
X_train_encoded = ce_target.fit_transform(X_train, y_train)

std = StandardScaler()
X_train_encoded = std.fit_transform(X_train_encoded)
X_train_encoded = pd.DataFrame(X_train_encoded,columns = X_train.columns)

"""### XGBoost"""

scale_pos_weight = sum(y == 0)/sum(y == 1) 
print('Scale Pos Weight : ', scale_pos_weight)

model = XGBClassifier(gamma=5, learning_rate=0.01, n_estimators=500, random_state=42,max_depth=3,
                                    scale_pos_weight=round(scale_pos_weight))
model.fit(X_train_encoded, y_train)

plot_importance(model)

y_pred_train = model.predict(X_train_encoded)
y_pred_train_prob = model.predict_proba(X_train_encoded)[:,1]
print('Train ')
performance(y_train,y_pred_train_prob>=0.6)
print('Test ')
X_test_encoded = ce_target.transform(X_test)
X_test_encoded = std.transform(X_test_encoded)
X_test_encoded = pd.DataFrame(X_test_encoded,columns = X_test.columns)
y_pred_test = model.predict(X_test_encoded)
y_pred_test_prob = model.predict_proba(X_test_encoded)[:,1]
performance(y_test,y_pred_test_prob >= 0.6)

test_encoded = ce_target.transform(test[num_col+cat_col])
test_encoded = std.transform(test_encoded)
test_encoded = pd.DataFrame(test_encoded,columns=X.columns)
test['prob'] = model.predict_proba(test_encoded)[:,1]
test['is_claim'] = np.where(test['prob'] > 0.6,1,0)
test[['policy_id','is_claim']].to_csv('sub_3.csv',index=0)

"""## Complete Data"""

ce_all = ce.TargetEncoder(cols=cat_col)
X_encoded = ce_all.fit_transform(X, y)
std_all = StandardScaler()
X_encoded = std_all.fit_transform(X_encoded)
X_encoded = pd.DataFrame(X_encoded,columns=X.columns)

model_all = XGBClassifier(gamma=5, learning_rate=0.01, n_estimators=500, random_state=42,max_depth=3,
                                    scale_pos_weight=round(scale_pos_weight))
model_all.fit(X_encoded, y)
y_pred = model_all.predict(X_encoded)
print('Train ')
performance(y,y_pred)
plot_importance(model_all)

y_pred_prob = model.predict_proba(X_encoded)[:,1]
for i in [j/100 for j in range(59,70)]:
  print(i,'-'*10)
  performance(y,y_pred_prob > i)

"""### Submission"""

test_encoded = ce_all.transform(test[num_col+cat_col])
test_encoded = std_all.transform(test_encoded)
test_encoded = pd.DataFrame(test_encoded,columns=X.columns)
test['prob'] = model_all.predict_proba(test_encoded)[:,1]
test['is_claim'] = np.where(test['prob'] >= 0.6,1,0)
test[['policy_id','is_claim']].to_csv('sub_3_all.csv',index=0)

test[['policy_id','is_claim']]

train.groupby(['is_claim']).agg({'policy_tenure':'describe'}).reset_index()

test[test['age_of_car']>0.35].shape

train['policy_tenure'].describe()